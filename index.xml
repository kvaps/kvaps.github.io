<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kvaps | personal blog</title>
    <link>https://kvaps.github.io/</link>
    <description>Recent content on kvaps | personal blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Dec 2016 03:10:52 +0000</lastBuildDate>
    
	<atom:link href="https://kvaps.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Backup storage for thousands of virtual machines using free tools</title>
      <link>https://kvaps.github.io/2020/05/backup-storage-for-thousands-of-virtual-machines-using-free-tools/</link>
      <pubDate>Fri, 29 May 2020 20:06:10 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2020/05/backup-storage-for-thousands-of-virtual-machines-using-free-tools/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://miro.medium.com/max/1400/0*A6SRoMPAkAf-RnRB.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Hi, recently I faced across an interesting task to setup a storage server for backup of a large number of block devices.&lt;/p&gt;
&lt;p&gt;Every week we back up all virtual machines in our cloud, so there is a need to be able handle thousands of backups and do it as fast and efficiently as possible.&lt;/p&gt;
&lt;p&gt;Unfortunately, the standard RAID5, RAID6 levels are not suitable due the fact that recovery process on such large disks as ours will be painfully long and most likely never finished successfully.&lt;/p&gt;
&lt;p&gt;Let’s consider what alternatives are:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.min.io/docs/minio-erasure-code-quickstart-guide.html&#34;&gt;Erasure Coding&lt;/a&gt;&lt;/strong&gt; — An analogue to RAID5, RAID6, but with a configurable parity level. Also the fault tolerance is performed not for whole block devices, but for each object separately. The easiest way to try Erasure Coding is to deploy &lt;a href=&#34;https://min.io/&#34;&gt;minio&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html&#34;&gt;DRAID&lt;/a&gt;&lt;/strong&gt; — is currently alpha feature of ZFS. Unlike RAIDZ, DRAID has a distributed parity block and uses all the disks in the array during recovery, this makes it better surviving for disk failures and provides faster recovery than standard RAID levels.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Configuring routing for MetalLB in L2 mode</title>
      <link>https://kvaps.github.io/2020/05/configuring-routing-for-metallb-in-l2-mode/</link>
      <pubDate>Thu, 14 May 2020 22:05:09 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2020/05/configuring-routing-for-metallb-in-l2-mode/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://miro.medium.com/max/1400/0*wI1GLh4MrCzuwiwB.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Not so far ago, I was faced with a quite unusual task of configuring routing for MetalLB. All would be nothing, since MetalLB usually does not require any additional configuration from user side, but in our case there is a fairly large cluster with a quite simple network configuration.&lt;/p&gt;
&lt;p&gt;In this article I will show you how to configure source-based and policy-based routing for the external network on your cluster.&lt;/p&gt;
&lt;p&gt;I will not dwell on installing and configuring MetalLB in detail, as I assume you already have some experience. Let’s understand the essence and configure the routing. So we have four cases:&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Connecting Gitlab with Harbor for automated token issuing</title>
      <link>https://kvaps.github.io/2020/04/connecting-gitlab-with-harbor-for-automated-token-issuing/</link>
      <pubDate>Fri, 24 Apr 2020 23:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2020/04/connecting-gitlab-with-harbor-for-automated-token-issuing/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://miro.medium.com/max/1400/1*rp7sSltmrBJ0lyHCenfmrw.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Gitlab CI have a nice feature to generate docker-registry tokens per each job, but this feature is working only for it’s own docker registry and does not working with an external ones, eg. Harbor, Nexus, Quay and etc.&lt;/p&gt;
&lt;p&gt;There is an opportunity to set-up external docker registry for Gitlab, it is well described in the documentation &lt;a href=&#34;https://docs.gitlab.com/ee/administration/packages/container_registry.html#use-an-external-container-registry-with-gitlab-as-an-auth-endpoint&#34;&gt;Use an external container registry with GitLab as an auth endpoint&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Proposed to configure brand new docker-registry with token based authentication. Harbor also uses docker-registry in backend, so that we could configure it, but problem is that both Gitlab and Harbor require to set their own parameters which are actually conflicts.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[awesome] My live in console</title>
      <link>https://kvaps.github.io/2020/04/awesome-my-live-in-console/</link>
      <pubDate>Thu, 09 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2020/04/awesome-my-live-in-console/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://i.redd.it/f6l0qbuy6rr41.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>How to describe 100 Gitlab jobs in 100 lines using Jsonnet</title>
      <link>https://kvaps.github.io/2020/01/how-to-describe-100-gitlab-jobs-in-100-lines-using-jsonnet/</link>
      <pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2020/01/how-to-describe-100-gitlab-jobs-in-100-lines-using-jsonnet/</guid>
      <description>&lt;p&gt;In addition to the &lt;a href=&#34;https://medium.com/@kvaps/trying-new-tools-for-building-and-automate-the-deployment-in-kubernetes-f96f9684e58&#34;&gt;previous article&lt;/a&gt; about deployment tools in Kubernetes, I want to tell you about how you can use Jsonnet to simplify the description of the jobs in your &lt;strong&gt;.gitlab-ci.yml&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://miro.medium.com/max/350/1*fVzTtRqdqlthR-kEGqbxLw.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;given&#34;&gt;Given&lt;/h2&gt;
&lt;p&gt;There is a monorepo in which:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;10 dockerfiles&lt;/li&gt;
&lt;li&gt;30 described deployments&lt;/li&gt;
&lt;li&gt;3 environments: devel, stage and prod&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;task&#34;&gt;Task&lt;/h2&gt;
&lt;p&gt;Configure a pipeline:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Building Docker images should be done by adding a git tag with a version number.&lt;/li&gt;
&lt;li&gt;Each deployment operation should be performed when pushing to the environment branch and only if files changed in a specific directory&lt;/li&gt;
&lt;li&gt;Each environment has its own gitlab-runner with a different tag that performs deployment only in this environment.&lt;/li&gt;
&lt;li&gt;Not any application should be deployed in each of the environments. We should describe the pipeline in order to be able to make exceptions.&lt;/li&gt;
&lt;li&gt;Some deployments use git submodule and should be run with the &lt;code&gt;GIT_SUBMODULE_STRATEGY=normal&lt;/code&gt; environment variable set.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Describing all this may seem like a real hell, but do not despair, armed with Jsonnet, we can easily do it.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Trying new tools for building and automating the deployment in Kubernetes</title>
      <link>https://kvaps.github.io/2020/01/trying-new-tools-for-building-and-automating-the-deployment-in-kubernetes/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2020/01/trying-new-tools-for-building-and-automating-the-deployment-in-kubernetes/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://miro.medium.com/max/3882/0*HJu_pzhe660WFJZ2&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Hi!&lt;br&gt;
Recently, many cool automation tools have been released both for building Docker images and for deploying to Kubernetes. In this regard, I decided to play with the Gitlab a little, study its capabilities and, of course, configure the pipeline.&lt;/p&gt;
&lt;p&gt;The source of inspiration for this work was the site &lt;a href=&#34;https://kubernetes.io/&#34;&gt;kubernetes.io&lt;/a&gt;, which is automatically generated from &lt;a href=&#34;github.com/kubernetes/website&#34;&gt;source code&lt;/a&gt;.&lt;br&gt;
For each new pullrequest the bot generates a preview version with your changes automatically and provides a link for review.&lt;/p&gt;
&lt;p&gt;I tried to build a similar process from scratch, but entirely built on Gitlab CI and free tools that I used to use to deploy applications in Kubernetes. Today, I finally will tell you more about them.&lt;/p&gt;
&lt;p&gt;The article will consider such tools as: &lt;strong&gt;Hugo&lt;/strong&gt;, &lt;strong&gt;qbec&lt;/strong&gt;, &lt;strong&gt;kaniko&lt;/strong&gt;, &lt;strong&gt;git-crypt&lt;/strong&gt; and &lt;strong&gt;GitLab CI&lt;/strong&gt; with dynamic environments feature.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[awesome] My work laptop</title>
      <link>https://kvaps.github.io/2019/12/awesome-my-work-laptop/</link>
      <pubDate>Sat, 14 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2019/12/awesome-my-work-laptop/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://i.redd.it/iyqfr4rghh441.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>“linstor_un” — New storage driver for OpenNebula</title>
      <link>https://kvaps.github.io/2019/07/linstor_un-new-storage-driver-for-opennebula/</link>
      <pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2019/07/linstor_un-new-storage-driver-for-opennebula/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://hsto.org/webt/e-/3z/h-/e-3zh-bbwjnljyazm68edln7muw.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Not so long ago, the guys from LINBIT presented their new SDS solution – Linstor. This is a fully free storage based on proven technologies: DRBD, LVM, ZFS. Linstor combines simplicity and well-developed architecture, which allows to achieve stability and quite impressive results.&lt;/p&gt;
&lt;p&gt;Today I would like to tell you a little about it and show how easy it can be integrated with OpenNebula using linstor_un – a new driver that I developed specifically for this purpose.&lt;/p&gt;
&lt;p&gt;Linstor in combination with OpenNebula will allow you to build a high-performance and reliable cloud, which you can easily deploy on your own infrastructure.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Store SSH Keys Securely</title>
      <link>https://kvaps.github.io/2019/05/store-ssh-keys-securely/</link>
      <pubDate>Tue, 14 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2019/05/store-ssh-keys-securely/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://miro.medium.com/max/852/0*JlXp6Hsyfcvk7LSi.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let me tell you how you can safely store SSH keys on a local machine, for not having a fear that some application can steal or decrypt them.
This article will be especially useful to those who have not found an elegant solution after the &lt;a href=&#34;https://latacora.singles/2018/08/03/the-default-openssh.html&#34;&gt;paranoia&lt;/a&gt; in 2018 and continue storing keys in &lt;code&gt;$HOME/.ssh&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To solve this problem, I suggest you using &lt;a href=&#34;https://keepassxc.org/&#34;&gt;KeePassXC&lt;/a&gt;, which is one of the best password managers, it is using strong encryption algorithms, and also it have an integrated SSH agent.&lt;/p&gt;
&lt;p&gt;This allows you to safely store all the keys directly in the password database and automatically add them to the system when it is opened. Once the base is closed, the use of SSH keys will also be impossible&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Installing Haproxy for Kubernetes</title>
      <link>https://kvaps.github.io/2019/04/installing-haproxy-for-kubernetes/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2019/04/installing-haproxy-for-kubernetes/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://miro.medium.com/max/619/1*HPqRvvMlCyxydro6ezCpow.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you want to make this scheme more safe you can add haproxy layer between keepalived and kube-apiserver.&lt;/p&gt;
&lt;p&gt;Just install haproxy package into your system, and add the next configuration into &lt;code&gt;/etc/haproxy/haproxy.cfg&lt;/code&gt; file&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Screen streaming to multiple devices via network</title>
      <link>https://kvaps.github.io/2019/04/screen-streaming-to-multiple-devices-via-network/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2019/04/screen-streaming-to-multiple-devices-via-network/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://miro.medium.com/max/3701/1*2P2MvNWAEffBGR85d8nJcQ.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I had a need to show dashboard with monitoring information on several screens in the office. There are several old Raspberry Pi Model B+ and a hypervisor with a virtually unlimited amount of resources.&lt;/p&gt;
&lt;p&gt;Apparently the Raspberry Pi Model B+ does not have enough power to keep the browser running constantly and draw a large amount of graphics in it, which is why the page is partially buggy and often crashes.&lt;/p&gt;
&lt;p&gt;I found a fairly simple and elegant solution, which I want to share with you.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Adding LDAP authentication to Kubernetes</title>
      <link>https://kvaps.github.io/2019/02/adding-ldap-authentication-to-kubernetes/</link>
      <pubDate>Tue, 26 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2019/02/adding-ldap-authentication-to-kubernetes/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://miro.medium.com/max/848/0*ZKnEqwk9W9lREHxf.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Short guide how to setup Keycloak for connect Kubernetes with your LDAP-server and import users and groups. It will allow you to configure RBAC and use auth-proxy to secure Kubernetes Dasboard and another applications, which have no authentification from begining.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Creating High Available Baremetal Kubernetes cluster with Kubeadm and Keepalived (More Simple Guide)</title>
      <link>https://kvaps.github.io/2018/12/creating-high-available-baremetal-kubernetes-cluster-with-kubeadm-and-keepalived-more-simple-guide/</link>
      <pubDate>Sun, 09 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2018/12/creating-high-available-baremetal-kubernetes-cluster-with-kubeadm-and-keepalived-more-simple-guide/</guid>
      <description>&lt;p&gt;This guide is updated version of my previous article &lt;a href=&#34;https://medium.com/@kvapss/creating-baremethal-kubernetes-ha-cluster-with-kubeadm-and-keepalived-simple-guide-c70ec4adf8ca&#34;&gt;Creating High Available Baremetal Kubernetes cluster with Kubeadm and Keepalived (Simple Guide)&lt;/a&gt;
Since &lt;strong&gt;v1.13&lt;/strong&gt; deployment has become much easier and more logical. Note that this article is my personal interpretation of official Creating Highly &lt;a href=&#34;https://kubernetes.io/docs/setup/independent/high-availability/&#34;&gt;Available Clusters with kubeadm&lt;/a&gt; for &lt;a href=&#34;https://kubernetes.io/docs/setup/independent/high-availability/#stacked-control-plane-nodes&#34;&gt;Stacked control plane nodes&lt;/a&gt; plus few more steps for Keepalived.&lt;/p&gt;
&lt;p&gt;If you have any questions, or something is not clear, please refer to the official documentation or ask the &lt;a href=&#34;https://www.google.com/&#34;&gt;Google&lt;/a&gt;. All steps described here in the short and simple form&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Creating Baremethal Kubernetes HA cluster with Kubeadm and Keepalived (Simple Guide)</title>
      <link>https://kvaps.github.io/2018/10/creating-baremethal-kubernetes-ha-cluster-with-kubeadm-and-keepalived-simple-guide/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2018/10/creating-baremethal-kubernetes-ha-cluster-with-kubeadm-and-keepalived-simple-guide/</guid>
      <description>&lt;p&gt;This guide is a free interpretation of official &lt;a href=&#34;https://kubernetes.io/docs/setup/independent/high-availability/&#34;&gt;Creating Highly Available Clusters with kubeadm&lt;/a&gt; for &lt;a href=&#34;https://kubernetes.io/docs/setup/independent/high-availability/#stacked-control-plane-nodes&#34;&gt;Stacked control plane nodes&lt;/a&gt;. I don’t like this difficult form which used there, so I wrote this article.&lt;/p&gt;
&lt;p&gt;If you have any questions, or something is not clear, please refer to the official documentation or ask the &lt;a href=&#34;https://www.google.com/&#34;&gt;Google&lt;/a&gt;. All steps described here in the short and simple form&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Install Kolab and integrate it with FreeIPA</title>
      <link>https://kvaps.github.io/2018/10/install-kolab-and-integrate-it-with-freeipa/</link>
      <pubDate>Thu, 04 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2018/10/install-kolab-and-integrate-it-with-freeipa/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://miro.medium.com/max/751/1*nR-RW_hUa89nBl1OmWaPuQ.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Here is written steps for install &lt;a href=&#34;https://kolab.org/&#34;&gt;Kolab Groupware&lt;/a&gt; server and integrate it with &lt;a href=&#34;https://www.freeipa.org/page/Main_Page&#34;&gt;FreeIPA&lt;/a&gt; server.&lt;/p&gt;
&lt;p&gt;Most of actions requires basic understanding in LDAP mechanism.
FreeIPA should be already installed before preparing Kolab installation.
We will connect only users from the existing tree (which provided by FreeIPA), and we will create new tree for the rest Kolab resources, like mail groups, shared mailboxes, etc.&lt;/p&gt;
&lt;p&gt;In the end, we will can authenticate them, edit their parameters via kolab-webadmin, and manage other resources.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Building a Network Bootable Server Farm for Kubernetes with LTSP</title>
      <link>https://kvaps.github.io/2018/10/building-a-network-bootable-server-farm-for-kubernetes-with-ltsp/</link>
      <pubDate>Tue, 02 Oct 2018 21:35:07 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2018/10/building-a-network-bootable-server-farm-for-kubernetes-with-ltsp/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://kubernetes.io/images/blog/2018-10-01-network-bootable-farm-with-ltsp/k8s+ltsp.svg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;In this post, I’m going to introduce you to a cool technology for Kubernetes, LTSP. It is useful for large baremetal Kubernetes deployments.&lt;/p&gt;
&lt;p&gt;You don’t need to think about installing an OS and binaries on each node anymore. Why? You can do that automatically through Dockerfile!&lt;/p&gt;
&lt;p&gt;You can buy and put 100 new servers into a production environment and get them working immediately - it’s really amazing!&lt;/p&gt;
&lt;p&gt;Intrigued? Let me walk you through how it works.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Deploying LINSTOR storage for Proxmox</title>
      <link>https://kvaps.github.io/2018/09/deploying-linstor-storage-for-proxmox/</link>
      <pubDate>Wed, 12 Sep 2018 21:36:59 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2018/09/deploying-linstor-storage-for-proxmox/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*cnj3wxTbCBWX6N_GGbgroA.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Few time ago LINBIT released their new solution LINSTOR which is providing orchestration tool for manage multiple DRBD-arrays.&lt;/p&gt;
&lt;p&gt;For example you can have few nodes, each one will have own LVM or ZFS pool, LINSTOR will automatically create new volumes there and replicate or distribute them using DRBD protocol.&lt;/p&gt;
&lt;p&gt;LINSTOR supports thin-provisioning, snapshots and many other interesting things.&lt;/p&gt;
&lt;p&gt;This solution is good suitable for virtual machines and containers.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Run kubernetes inside LXC container</title>
      <link>https://kvaps.github.io/2018/08/run-kubernetes-inside-lxc-container/</link>
      <pubDate>Wed, 22 Aug 2018 21:36:47 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2018/08/run-kubernetes-inside-lxc-container/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://cdn-images-1.medium.com/max/800/1*YoK1cRYjSmssxRSBBHZYfg.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I can tell you how you can run kubernetes master in LXC container, I use Proxmox and it is working really fine, this manual can serve as an alternative way for the classical several masters deployment.
In this case you can have only one master, and still have all the features of multimater.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Easy way for install Mikrotik’s Cloud Hosted Router on any Cloud VM</title>
      <link>https://kvaps.github.io/2018/02/easy-way-for-install-mikrotiks-cloud-hosted-router-on-any-cloud-vm/</link>
      <pubDate>Tue, 06 Feb 2018 12:53:35 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2018/02/easy-way-for-install-mikrotiks-cloud-hosted-router-on-any-cloud-vm/</guid>
      <description>&lt;p&gt;Many cloud providers not allows uploading ISOs and not provides any option for install custom OS. This is not a problem, because I’ll show you how you can prepare Mikrotik VM on any cloud in easy 5 steps.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Zabbix: solve memory and cpu load monitoring issues inside LXC containers</title>
      <link>https://kvaps.github.io/2017/11/zabbix-solve-memory-and-cpu-load-monitoring-issues-inside-lxc-containers/</link>
      <pubDate>Wed, 29 Nov 2017 12:53:18 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2017/11/zabbix-solve-memory-and-cpu-load-monitoring-issues-inside-lxc-containers/</guid>
      <description>&lt;p&gt;Zabbix have some problems with memory collecting from cgroups limited containers.
If you using Promxox, you know what I mean: The available memory collected worng without calculating buffers and cache memory.
Zabbix have &lt;a href=&#34;https://medium.com/r/?url=https%3A%2F%2Fsupport.zabbix.com%2Fbrowse%2FZBX-12164&#34;&gt;bug report&lt;/a&gt;, but it seems that no one don’t want to fix it soon.
So let’s fix it together byself.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Projects Archive</title>
      <link>https://kvaps.github.io/projects-archive/</link>
      <pubDate>Tue, 27 Dec 2016 03:10:52 +0000</pubDate>
      
      <guid>https://kvaps.github.io/projects-archive/</guid>
      <description>ArtRadio.fm 
Electronic music radio station (abandoned)
 ArtPredel.ru 
The most unusual art from the web (abandoned)</description>
    </item>
    
    <item>
      <title>ONLYOFFICE configuration for docker-compose (and letsencrypt).</title>
      <link>https://kvaps.github.io/2016/12/onlyoffice-configuration-for-docker-compose-and-letsencrypt./</link>
      <pubDate>Wed, 14 Dec 2016 03:55:37 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2016/12/onlyoffice-configuration-for-docker-compose-and-letsencrypt./</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Run communityserver container, and get &lt;code&gt;onlyoffice.conf&lt;/code&gt; from it:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run -name communityserver -i -t -d onlyoffice/communityserver&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# wait 1-2 minutes.&lt;/span&gt;
sudo docker exec -i -t communityserver /bin/bash -c &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cat /etc/nginx/sites-enabled/onlyoffice&amp;#39;&lt;/span&gt; &amp;gt; onlyoffice.conf&lt;span style=&#34;color:#e6db74&#34;&gt;`&lt;/span&gt;
sudo docker rm -fv communityserver
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Build your own failover cloud based on OpenNebula with Ceph, MariaDB Galera Cluster and OpenvSwitch [machine translation]</title>
      <link>https://kvaps.github.io/2015/11/build-your-own-failover-cloud-based-on-opennebula-with-ceph-mariadb-galera-cluster-and-openvswitch-machine-translation/</link>
      <pubDate>Mon, 16 Nov 2015 16:45:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2015/11/build-your-own-failover-cloud-based-on-opennebula-with-ceph-mariadb-galera-cluster-and-openvswitch-machine-translation/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/1b8/185/6c4/1b81856c42da42ba903e85e1653969e4.png&#34; alt=&#34;&#34;&gt;
This time I would like to tell how to configure this subject, in a particular each separate component as a result to receive the own, expanded, otkazoustoycheavy cloud based on OpenNebula. In this article I will consider the next moments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://weekly-geekly.github.io/articles/270187/index.html#ceph&#34;&gt;Install Ceph, distributed storage&lt;/a&gt;&lt;/strong&gt;. &lt;em&gt;(I will describe the installation of a two-tier storage with a caching pool of SSDs)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://weekly-geekly.github.io/articles/270187/index.html#galera&#34;&gt;Install MySQL, Galera Cluster with master replication&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://weekly-geekly.github.io/articles/270187/index.html#openvswitch&#34;&gt;Installing OpenvSwitch soft switch&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://weekly-geekly.github.io/articles/270187/index.html#opennebula&#34;&gt;Installing directly OpenNebula itself&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://weekly-geekly.github.io/articles/270187/index.html#pacemaker&#34;&gt;Configuring Failover Cluster&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://weekly-geekly.github.io/articles/270187/index.html#configuration&#34;&gt;Initial configuration&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The topics themselves are very interesting, so even if you are not interested in the final goal, but you are interested in setting up a separate component. You are welcome under the cut.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Installing CentOS on ZFS in UEFI [machine translation]</title>
      <link>https://kvaps.github.io/2015/10/installing-centos-on-zfs-in-uefi-machine-translation/</link>
      <pubDate>Tue, 13 Oct 2015 15:37:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2015/10/installing-centos-on-zfs-in-uefi-machine-translation/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/fcc/619/ae4/fcc619ae4bb7418980f542ed02978583.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I decided to try ZFS here the other day, but I did not find a detailed and simple manual on how to implement it on CentOS, I decided to correct the situation. In addition, I wanted to install all this in EFI mode. - not to stand still? And at the same time understand for yourself how &lt;a href=&#34;https://ru.wikipedia.org/wiki/Dynamic_Kernel_Module_Support&#34;&gt;DKMS&lt;/a&gt; works, as well as aspects of manual installation of RPM-based distributions.
ZFS was not chosen by chance either, since it was planned to deploy a hypervisor on this machine and use zvol to store images of virtual machines. I wanted something more than a software raid + lvm or simple file storage of images, something like &lt;a href=&#34;https://ru.wikipedia.org/wiki/Ceph_File_System&#34;&gt;ceph&lt;/a&gt;, but for one host this is too bold. Looking ahead to say that I was very pleased with this file system, its performance and all its &lt;a href=&#34;http://xgu.ru/wiki/ZFS&#34;&gt;chips&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Customize keyboard shortcuts in Linux like Mac OS X [machine translation]</title>
      <link>https://kvaps.github.io/2015/09/customize-keyboard-shortcuts-in-linux-like-mac-os-x-machine-translation/</link>
      <pubDate>Wed, 09 Sep 2015 16:30:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2015/09/customize-keyboard-shortcuts-in-linux-like-mac-os-x-machine-translation/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/8f1/55e/18d/8f155e18dc4b4f1f80113941c5ad32ab.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Previously, I quite often had a situation where you simultaneously work in a terminal and, for example, in a browser.
After several hours of work, you start to get confused and in the terminal instead of [Ctrl] + [Shift] + [C], press [Ctrl] + [C], and vice versa in the browser. As a result, in the terminal you get an interrupt and in the browser, instead of the expected effect, your debugger is slowly loaded.
One fine moment it got me and I decided it was time to change something&amp;hellip;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Forwarding USB to a virtual network via UsbRedir and QEMU [machine translation]</title>
      <link>https://kvaps.github.io/2015/08/forwarding-usb-to-a-virtual-network-via-usbredir-and-qemu-machine-translation/</link>
      <pubDate>Thu, 20 Aug 2015 11:55:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2015/08/forwarding-usb-to-a-virtual-network-via-usbredir-and-qemu-machine-translation/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://hsto.org/files/e6a/1bc/05d/e6a1bc05d70c460399d3276fdec28d2c.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;To date, there are quite a few ways to forward a USB device to another computer or virtual machine over the network.&lt;/p&gt;
&lt;p&gt;Of the most popular, hardware such as AnywhereUSB and purely software products, from those that I tried myself: USB Redirector and USB / IP.&lt;/p&gt;
&lt;p&gt;I would like to tell you about another interesting method that works directly with the QEMU emulator.&lt;/p&gt;
&lt;p&gt;It is also part of the spice project, officially supported by RedHat.&lt;/p&gt;
&lt;p&gt;UsbRedir, is an open protocol for forwarding usb-devices via tcp to a remote virtual server, developed with the support of RedHat in the framework of the spice project. But as it turned out they can be quite successfully used without spice. The server is usbredirserver, which fumbles a usb device on a specific port, and QEMU itself as a client, which emulates the connection of an exported usb device to a specific usb controller of your virtual machine. Thanks to this approach, absolutely any OS can be used as a guest system, since it does not even know that the device is remotely forwarded, and all the logic rests on QEMU.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kolab Groupware (Part 2 - Installation) [machine translation]</title>
      <link>https://kvaps.github.io/2015/07/kolab-groupware-part-2-installation-machine-translation/</link>
      <pubDate>Sat, 18 Jul 2015 14:17:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2015/07/kolab-groupware-part-2-installation-machine-translation/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/ee8/922/938/ee892293882e4e2487c48354109305bb.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;If you still do not know what Kolab is, then you probably want to read the &lt;a href=&#34;https://weekly-geekly.github.io/articles/260469/index.html&#34;&gt;first article&lt;/a&gt;, where I did a detailed review of this rather functional and completely free mail server with a beautiful web-muzzle.
This time we will install it.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Kolab Groupware (Part 1 - Overview) [machine translation]</title>
      <link>https://kvaps.github.io/2015/07/kolab-groupware-part-1-overview-machine-translation/</link>
      <pubDate>Fri, 17 Jul 2015 15:17:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2015/07/kolab-groupware-part-1-overview-machine-translation/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/3b1/7cb/b50/3b17cbb50147480da0cfab3dc4154b05.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Hi, Habr! I want to tell you about a rather interesting and functional replacement for MS Exchange, completely free and also with a beautiful web-muzzle. The conversation will be about Kolab - a free mail server with support for collaboration, calendars, to-do lists, WebDAV, ActiveSync synchronization and other goodies that can be used both for work and for home.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Carefully, in a post a lot of pictures&amp;hellip;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>We lift the VPN tunnel from the world home bypassing NAT [machine translation]</title>
      <link>https://kvaps.github.io/2014/03/we-lift-the-vpn-tunnel-from-the-world-home-bypassing-nat-machine-translation/</link>
      <pubDate>Tue, 18 Mar 2014 14:51:00 +0000</pubDate>
      
      <guid>https://kvaps.github.io/2014/03/we-lift-the-vpn-tunnel-from-the-world-home-bypassing-nat-machine-translation/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/getpro/habr/post_images/427/d2e/abc/427d2eabc3adcf37fdd642660f5aa09a.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;I want to tell you about how having your VPS server on the Internet, you can raise a tunnel to your home network. And do not pay at the same time for a static IP provider, and even being behind a NAT, still make your home services available on the Internet.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>